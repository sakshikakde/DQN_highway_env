{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"run_training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvkkm2MUTZ1Uhk1haG7A5p"},"kernelspec":{"name":"python3","display_name":"Python 3.6.9 64-bit"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"cells":[{"cell_type":"markdown","source":["# Mount the drive and install gym-0.21.0 and highway environment"],"metadata":{"id":"Xv6wr1n2E9t_"}},{"cell_type":"code","execution_count":5,"source":["import sys\n","import os\n","try:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive/')\n","  project_path = 'ENPM690/Project/DQN_highway_env'\n","  sys.path.append(os.path.join('/content/gdrive/MyDrive', project_path))\n","\n","  !pip uninstall gym\n","  !pip install gym==0.21.0\n","  !pip install highway-env\n","  \n","except:\n","  print(\"Run only for google colab\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Run only for google colab\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfS49542EyTL","executionInfo":{"status":"ok","timestamp":1650472176823,"user_tz":240,"elapsed":18480,"user":{"displayName":"Sakshi Kakde","userId":"06060460815794748989"}},"outputId":"6549f8d6-2e8e-42b9-da73-89373d2043b3"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"UDLSeFSqFocP"}},{"cell_type":"code","execution_count":6,"source":["from common_utils import *\n","from models.dqn_conv_v1 import DQN as DQN\n","from train import *"],"outputs":[],"metadata":{"id":"JQVhQT9YFODO"}},{"cell_type":"code","execution_count":7,"source":["def main():\n","    opt = parse_opts()\n","    print(opt)\n","\n","    if not os.path.exists(opt.save_folder):\n","        os.mkdir(opt.save_folder)\n","    if not os.path.exists(os.path.join(opt.save_folder, opt.env)):\n","        os.mkdir(os.path.join(opt.save_folder, opt.env))\n","\n","    timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime())\n","    csv_file_name  = os.path.join(opt.save_folder, f'{timestamp}_stats.csv')\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    em = HighwayEnvManager(device)\n","    strategy = EpsilonGreedyStrategy(opt.eps_start, opt.eps_end, opt.eps_decay)\n","    agent = Agent(strategy, em.num_actions_available(), device)\n","    memory = ReplayMemory(opt.memory_size)\n","    \n","    policy_net = DQN(em.get_screen_height(), em.get_screen_width(), em.get_screen_stack(), em.num_actions_available()).to(device)\n","    target_net = DQN(em.get_screen_height(), em.get_screen_width(), em.get_screen_stack(), em.num_actions_available()).to(device)\n","    target_net.load_state_dict(policy_net.state_dict())\n","    target_net.eval()\n","\n","    optimizer = optim.Adam(params=policy_net.parameters(), lr=opt.lr)\n","    criterion = nn.MSELoss()\n","\n","    episode_durations = []\n","    episode_rewards = []\n","    best_reward = 0\n","    best_state = None\n","\n","    for episode in range(opt.num_episodes):\n","        duration, reward, loss_epoch = train_epoch(opt, em, agent, policy_net, target_net, memory, device, optimizer, criterion)\n","        episode_durations.append(duration)\n","        episode_rewards.append(reward)\n","\n","        write2csv(filename = csv_file_name, duration = duration, reward = reward, loss = loss_epoch)\n","        moving_avg_period = 50\n","        avg_reward = get_moving_average(moving_avg_period, episode_rewards)\n","        print(\"Episode\", episode, \"\\n\",\n","        moving_avg_period, \"episode average reward: \", \"{:.4f}\".format(avg_reward[-1]), \" | currect episode reward: \", \"{:.4f}\".format(reward), \"| duration :\", duration)\n","\n","        state = {'epoch': episode, 'state_dict': policy_net.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}\n","\n","        if avg_reward[-1] > best_reward:\n","            best_reward = avg_reward[-1]\n","            best_state = state\n","\n","        if episode % opt.target_update == 0:\n","            target_net.load_state_dict(policy_net.state_dict())\n","        \n","        if episode % opt.save_interval == opt.save_interval - 1:\n","            timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime())\n","            torch.save(best_state, os.path.join(os.path.join(opt.save_folder, opt.env),\n","                                          f'{opt.env}-Episode-{episode}-Reward-{ avg_reward[-1]}_{timestamp}.pth'))\n","            print(\"Model saved with average reward \",best_reward)\n","            best_reward = 0"],"outputs":[],"metadata":{"id":"zgjIs-rIFuTA"}},{"cell_type":"code","execution_count":8,"source":["main()"],"outputs":[{"output_type":"stream","name":"stderr","text":["usage: ipykernel_launcher [-h] [-f F] [--env ENV] [--batch_size BATCH_SIZE]\n","                          [--gamma GAMMA] [--eps_start EPS_START]\n","                          [--eps_end EPS_END] [--eps_decay EPS_DECAY]\n","                          [--target_update TARGET_UPDATE]\n","                          [--memory_size MEMORY_SIZE] [--lr LR]\n","                          [--num_episodes NUM_EPISODES]\n","                          [--save_interval SAVE_INTERVAL]\n","                          [--save_folder SAVE_FOLDER]\n","                          [--model_name MODEL_NAME]\n","ipykernel_launcher: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"0e4b4648-b306-496c-a95f-43771be84c78\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/tmp/tmp-3369u4OQOOFBVICr.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"2","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIFF2jTuJoQH","outputId":"795418a6-6448-472c-ad63-e97e2d0fc7ef"}}]}